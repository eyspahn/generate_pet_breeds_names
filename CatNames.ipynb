{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a single long string of strain names separated by newline chars\n",
    "with open('cat_names.csv') as f:\n",
    "    file = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import re\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_len = 100\n",
    "file_len = len(file)\n",
    "def random_chunk():\n",
    "    '''filelen is length of chars in file'''\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1,-1))\n",
    "        output, hidden = self.gru(input.view(1,1,-1) ,hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 10\n",
      " 11\n",
      " 12\n",
      " 39\n",
      " 40\n",
      " 41\n",
      "[torch.LongTensor of size 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def char_tensor(string_):\n",
    "    tensor = torch.zeros(len(string_)).long()\n",
    "    for c in range(len(string_)):\n",
    "        tensor[c] = all_characters.index(string_[c])\n",
    "    return Variable(tensor)\n",
    "\n",
    "print(char_tensor('abcDEF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating\n",
    "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden()\n",
    "    prime_input = char_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "    \n",
    "    for p in range(len(prime_str)-1):\n",
    "        _,hidden = decoder(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char_tensor(predicted_char)\n",
    "        \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s/60)\n",
    "    s -= m*60\n",
    "    return '%dm %ds' % (m,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden()\n",
    "    decoder.zero_grad()\n",
    "    loss=0\n",
    "    \n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[c], hidden)\n",
    "        loss += criterion(output, target[c])\n",
    "        \n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / chunk_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 13s (100 5%) 2.4004]\n",
      "RpRe\n",
      "Cacbebt\n",
      "Maslie Bela\n",
      "Bele\n",
      "Torgioo\n",
      "Omdie\n",
      "Telta\n",
      "Kuer\n",
      "Dia\n",
      "Tager\n",
      "Belew Frroele\n",
      "Omino\n",
      "Trujiga\n",
      "Boow\n",
      "Fes \n",
      "\n",
      "[0m 27s (200 10%) 2.3936]\n",
      "Ra Bora\n",
      "Syore\n",
      "Zacy\n",
      "Omi Sani\n",
      "Eliro\n",
      "Hoo\n",
      "Hotty\n",
      "Felie\n",
      "Koon\n",
      "Sesterolon\n",
      "Geander\n",
      "Mrano\n",
      "Grarue\n",
      "Bosten\n",
      "Secy\n",
      "Pr \n",
      "\n",
      "[0m 40s (300 15%) 2.3351]\n",
      "Ragdy\n",
      "Sabu\n",
      "Mald\n",
      "Tosppin\n",
      "Lalc\n",
      "Loxin\n",
      "Abnan Doard\n",
      "Malli\n",
      "Fren\n",
      "Alla\n",
      "Liger\n",
      "Chortorla\n",
      "Dassie\n",
      "Hargie\n",
      "Oliea\n",
      "Ch \n",
      "\n",
      "[0m 55s (400 20%) 2.5958]\n",
      "Ron\n",
      "Dackrie\n",
      "Cack\n",
      "Jink\n",
      "Poppy\n",
      "Ild\n",
      "Copadro\n",
      "Wumber Tumi\n",
      "Missas\n",
      "Ney\n",
      "Sperat\n",
      "Hoze\n",
      "Moja\n",
      "Molly\n",
      "Jack\n",
      "Molly\n",
      "Alic \n",
      "\n",
      "[1m 8s (500 25%) 2.2254]\n",
      "Rufla\n",
      "Rilly\n",
      "Kayty\n",
      "Jaxget\n",
      "Samale\n",
      "Jem\n",
      "Dellan\n",
      "Stleris\n",
      "Mixie\n",
      "Lek\n",
      "Lilo\n",
      "Miny\n",
      "Dennin\n",
      "Ever\n",
      "Zee\n",
      "Nipollda\n",
      "Tigge \n",
      "\n",
      "[1m 24s (600 30%) 2.3733]\n",
      "Rope\n",
      "Sade\n",
      "Bubbby\n",
      "Leeki\n",
      "Ozzie\n",
      "Sherace\n",
      "Olive\n",
      "Mata\n",
      "Burter\n",
      "Kidna\n",
      "Freusty\n",
      "Sluggin\n",
      "Tasie\n",
      "Lokie\n",
      "Cherleted\n",
      "Ki \n",
      "\n",
      "[1m 38s (700 35%) 2.0252]\n",
      "Run\n",
      "Pricem\n",
      "Missy\n",
      "Abby\n",
      "Luva\n",
      "Woo\n",
      "Frudley\n",
      "Laisa\n",
      "Mucks\n",
      "Moggy\n",
      "Ayalla\n",
      "Chani\n",
      "Ala\n",
      "Golf\n",
      "Jamh\n",
      "Finie\n",
      "Kriper\n",
      "Than \n",
      "\n",
      "[1m 52s (800 40%) 2.0167]\n",
      "Riso\n",
      "Deisha\n",
      "Miss Dimbus\n",
      "Bloe\n",
      "Simmin\n",
      "Banie\n",
      "Caster\n",
      "Kiki\n",
      "Lily\n",
      "Carson\n",
      "Jenne\n",
      "Susty\n",
      "Mia\n",
      "Blacky\n",
      "Boby\n",
      "Elma\n",
      "Sa \n",
      "\n",
      "[2m 5s (900 45%) 2.0356]\n",
      "Raccie\n",
      "Ellie\n",
      "Baby\n",
      "Bean\n",
      "Olille\n",
      "Asri\n",
      "Nuppy\n",
      "Lucyt\n",
      "Vuckin\n",
      "Norellie\n",
      "Max\n",
      "Ollie\n",
      "Dutter\n",
      "Puppuck\n",
      "Oscu\n",
      "Max\n",
      "Sima \n",
      "\n",
      "[2m 17s (1000 50%) 2.5378]\n",
      "Rou\n",
      "Pogelrie\n",
      "Oni \"\"\"\"\"\"\"\"Ick Mons\n",
      "Mirly\n",
      "Evir\n",
      "Isia\n",
      "Howen Leaur\n",
      "Mazzy\n",
      "Stestie\n",
      "Ribblebe\n",
      "Hopert\n",
      "Puff\n",
      "Bigg \n",
      "\n",
      "[2m 30s (1100 55%) 2.0321]\n",
      "Rumpkig\n",
      "Tilma\n",
      "Arti\n",
      "Jeebester\n",
      "Jessy\n",
      "Dolvout\n",
      "Squilley\n",
      "Dibasio\n",
      "Roli\n",
      "Luki\n",
      "Mas\n",
      "Missen\n",
      "Cheley\n",
      "Pox\n",
      "Skye\n",
      "Coop \n",
      "\n",
      "[2m 44s (1200 60%) 2.0806]\n",
      "RPimpet\n",
      "Peeper\n",
      "MicJas\n",
      "Mex\n",
      "Shooma\n",
      "Mirie Beis\n",
      "Magger\n",
      "Pendens\n",
      "Mamper\n",
      "Marcal\n",
      "Lilly\n",
      "Miskey\n",
      "Ellia\n",
      "Cammet\n",
      "Ar \n",
      "\n",
      "[2m 56s (1300 65%) 1.7971]\n",
      "Rcker\n",
      "Trinkige\n",
      "Katie\n",
      "Missy\n",
      "Mussa\n",
      "Wina\n",
      "Kanga\n",
      "Tabby\n",
      "Frank\n",
      "Misu Frann\n",
      "Timba\n",
      "Pernel\n",
      "Orah\n",
      "Shamba\n",
      "Besmi\n",
      "Kea \n",
      "\n",
      "[3m 8s (1400 70%) 1.7235]\n",
      "Roo\n",
      "Phoabe\n",
      "Max\n",
      "Cleo\n",
      "Tuxy\n",
      "Samiles\n",
      "Sam\n",
      "Maxwell\n",
      "Pew\n",
      "Bartie\n",
      "Peo\n",
      "Maci\n",
      "Peppen\n",
      "Shak\n",
      "Fely\n",
      "Cherlinx\n",
      "Lolly\n",
      "Moni \n",
      "\n",
      "[3m 22s (1500 75%) 2.1309]\n",
      "Rasin\n",
      "Charlie\n",
      "Buzzu\n",
      "Chorer\n",
      "Borgley\n",
      "Emma\n",
      "Bong\n",
      "Anguarin\n",
      "Goneda\n",
      "Jo\n",
      "Spigy\n",
      "Scolly\n",
      "Cremo\n",
      "Topkin\n",
      "Toby\n",
      "Sark\n",
      "O \n",
      "\n",
      "[3m 34s (1600 80%) 2.2665]\n",
      "Rogelly\n",
      "Ilia\n",
      "Spyla\n",
      "Casa\n",
      "Pritel\n",
      "Georger\n",
      "Alart\n",
      "Boo\n",
      "Milke\n",
      "Sasha\n",
      "Gyras\n",
      "Loki\n",
      "Ballie\n",
      "Wiger\n",
      "Belly\n",
      "Mistle\n",
      "Bel \n",
      "\n",
      "[3m 46s (1700 85%) 2.0496]\n",
      "Ruiga\n",
      "Pepper\n",
      "Chla\n",
      "Hasaper\n",
      "Noga\n",
      "Max\n",
      "Lucy\n",
      "Jombick\n",
      "Chlo\n",
      "Sami\n",
      "Snezzy\n",
      "Maxie\n",
      "Charlow\n",
      "Artomm\n",
      "Marena\n",
      "Cala\n",
      "Mis \n",
      "\n",
      "[3m 59s (1800 90%) 2.2571]\n",
      "Ru\n",
      "Tigger\n",
      "Rilo\n",
      "Shadow\n",
      "Allex\n",
      "Charle\n",
      "Bello\n",
      "Willow\n",
      "Cali\n",
      "Emon\n",
      "Sammy\n",
      "Maggie\n",
      "Verline\n",
      "Sparrcty\n",
      "Missy\n",
      "Tarotte \n",
      "\n",
      "[4m 13s (1900 95%) 1.7728]\n",
      "Res\n",
      "Annier\n",
      "Icus\n",
      "Mack\n",
      "Charlot\n",
      "Ne\n",
      "Signiti\n",
      "Jack\n",
      "Junma\n",
      "Cildora\n",
      "Bicon\n",
      "Penelop\n",
      "Thar\n",
      "Vetters\n",
      "Louiston\n",
      "Sumes\n",
      " \n",
      "\n",
      "[4m 25s (2000 100%) 1.8419]\n",
      "Ra\n",
      "Poton\n",
      "Jazz\n",
      "Sasha\n",
      "Larar\n",
      "Stestor\n",
      "Ella\n",
      "Pibbel\n",
      "Boodle\n",
      "Sircuy\n",
      "FEur\n",
      "Perella\n",
      "Marlinen\n",
      "Hango\n",
      "Stella\n",
      "Zoo\n",
      "Zi \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every=10\n",
    "hidden_size = 100\n",
    "n_layers = 1\n",
    "lr = 0.005\n",
    "\n",
    "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses=[]\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    try:\n",
    "        loss = train(*random_training_set())\n",
    "        loss_avg += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "            print(evaluate('R', 100), '\\n')\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            all_losses.append(loss_avg / plot_every)\n",
    "            loss_avg = 0\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill\n",
      "Lulu\n",
      "Pronie\n",
      "Stella\n",
      "Pepper\n",
      "Rocky\n",
      "Parro\n",
      "Bella\n",
      "Patch\n",
      "Samiley\n",
      "Stella\n",
      "Sammi\n",
      "Suokie\n",
      "Sanda\n",
      "Sam\n",
      "Linz\n",
      "Pip\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('f', 100, temperature=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw\n",
      "Savia\n",
      "Sansey\n",
      "Sammet Ceramin\n",
      "Erlo\n",
      "Merro\n",
      "Bartch\n",
      "Potty\n",
      "Seanie\n",
      "Isaby\n",
      "Spother\n",
      "Mink\n",
      "Gracie\n",
      "Cetty\n",
      "Bean\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('r', 100, temperature=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ck\n",
      "Bennur\n",
      "Habet\n",
      "Poppy\n",
      "Blooa\n",
      "Hawballea\n",
      "Zoe\n",
      "Luo\n",
      "Mingian\n",
      "Dalsie Samine\n",
      "Snow\n",
      "Sander\n",
      "Maspy\n",
      "Minkey\n",
      "Sam\n",
      "Zerinora\n",
      "Zoosh\n",
      "Vicrina\n",
      "Blue\n",
      "Marple\n",
      "Hanuter\n",
      "Fio\n",
      "Annie\n",
      "Cachur\n",
      "Ravin\n",
      "Landy\n",
      "Pappyn\n",
      "Mandy\n",
      "Linceld\n",
      "Lucy\n",
      "Theo\n",
      "I\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('c', 200, temperature=0.8)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...So what happens if we input unique names -- I didn't take out names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
